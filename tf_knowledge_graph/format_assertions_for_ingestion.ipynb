{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Format assertions for Neo4j ingestion\n",
    "This notebook formats the filtered network for ingestion into the Neo4j database, which is necessary to run the KG UI. \n",
    "\n",
    "Also included is the option to plot histogram distributions of source edges, target edges, and edge significance in the unfiltered network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up assertions directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assertions_dir = './kg_assertions_for_neo4j'\n",
    "\n",
    "if not os.path.exists(assertions_dir):\n",
    "    os.makedirs(assertions_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose a network to format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_type = 'node_weighted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload the filtered edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network_edge_file = f'./filtered_edge_list/large/{network_type}/edge_list_filtered.csv'\n",
    "final_edge_list = pd.read_csv(network_edge_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add URI metadata to each TF node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the code in `notebooks/serialization.ipynb` to find a gene ID associated with each gene symbol, and then associate each node with a URI that points to a web page for that gene. \n",
    "\n",
    "Print statements are added in `get_gene_metadata` to identify genes that aren't found in the NCBI library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_save_read(url, file, reader=pd.read_csv, sep='\\t', **kwargs):\n",
    "  ''' Download file from {url}, save it to {file}, and subsequently read it with {reader} using pandas options on {**kwargs}.\n",
    "  '''\n",
    "  if not os.path.exists(file):\n",
    "    if os.path.dirname(file):\n",
    "      os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    df = reader(url, sep=sep, index_col=None)\n",
    "    df.to_csv(file, sep=sep, index=False)\n",
    "  return pd.read_csv(file, sep=sep, **kwargs)\n",
    "\n",
    "# get the NCBI gene info\n",
    "organism = \"Mammalia/Homo_sapiens\"\n",
    "url = 'ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/{}.gene_info.gz'.format(organism)\n",
    "file = '{}.gene_info.tsv'.format(organism)\n",
    "\n",
    "ncbi_gene = fetch_save_read(url, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_split(record):\n",
    "    ''' NCBI Stores Nulls as '-' and lists '|' delimited\n",
    "    '''\n",
    "    if record in {'', '-'}:\n",
    "        return set()\n",
    "    return set(record.split('|'))\n",
    "\n",
    "def supplement_dbXref_prefix_omitted(ids):\n",
    "    ''' NCBI Stores external IDS with Foreign:ID while most datasets just use the ID\n",
    "    '''\n",
    "    for id in ids:\n",
    "        # add original id\n",
    "        yield id\n",
    "        # also add id *without* prefix\n",
    "        if ':' in id:\n",
    "            yield id.split(':', maxsplit=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find all synonyms for each gene\n",
    "ncbi_gene['All_synonyms'] = [\n",
    "    set.union(\n",
    "      maybe_split(gene_info['Symbol']),\n",
    "      maybe_split(gene_info['Symbol_from_nomenclature_authority']),\n",
    "      maybe_split(str(gene_info['GeneID'])),\n",
    "      maybe_split(gene_info['Synonyms']),\n",
    "      maybe_split(gene_info['Other_designations']),\n",
    "      maybe_split(gene_info['LocusTag']),\n",
    "      set(supplement_dbXref_prefix_omitted(maybe_split(gene_info['dbXrefs']))),\n",
    "    )\n",
    "    for _, gene_info in ncbi_gene.iterrows()\n",
    "  ]\n",
    "\n",
    "# look up by synonym\n",
    "synonyms, gene_id = zip(*{\n",
    "    (synonym, gene_info['GeneID'])\n",
    "    for _, gene_info in ncbi_gene.iterrows()\n",
    "    for synonym in gene_info['All_synonyms']\n",
    "  })\n",
    "\n",
    "ncbi_lookup_syn = pd.Series(gene_id, index=synonyms)\n",
    "\n",
    "# look up by symbol incl capitalized\n",
    "symbols, cap, gene_id = zip(*{\n",
    "    (gene_info['Symbol'], gene_info['Symbol'].upper(), gene_info['GeneID'])\n",
    "    for _, gene_info in ncbi_gene.iterrows()\n",
    "  })\n",
    "\n",
    "ncbi_lookup_sym = pd.Series(gene_id, index=symbols)\n",
    "ncbi_lookup_sym_cap = pd.Series(gene_id, index=cap)\n",
    "\n",
    "# find duplicate synonyms\n",
    "index_values = ncbi_lookup_syn.index.value_counts()\n",
    "ambiguous = index_values[index_values > 1]\n",
    "\n",
    "# disambiguate \n",
    "ncbi_lookup_syn_disambiguated = ncbi_lookup_syn[(\n",
    "(ncbi_lookup_syn.index == ncbi_lookup_syn) | (~ncbi_lookup_syn.index.isin(ambiguous))\n",
    ")]\n",
    "\n",
    "sym_dict = ncbi_lookup_sym.to_dict()\n",
    "syn_dict_cap = ncbi_lookup_sym_cap.to_dict()\n",
    "syn_dict = ncbi_lookup_syn_disambiguated.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_lookup(gene):\n",
    "    ''' Look up the gene ID associated with a gene\n",
    "    '''\n",
    "    gene_id = sym_dict.get(gene)\n",
    "    if gene_id: return str(gene_id)\n",
    "\n",
    "    gene_id = syn_dict_cap.get(gene)\n",
    "    if gene_id: return str(gene_id)\n",
    "    \n",
    "    return str(syn_dict.get(gene))\n",
    "\n",
    "all_genes = {}\n",
    "gene_ids = set()\n",
    "\n",
    "def get_gene_meta(gene):\n",
    "    ''' Find the URI for each gene using the gene ID\n",
    "    '''\n",
    "    if gene in all_genes:\n",
    "        return all_genes[gene]\n",
    "    else:\n",
    "        gene_id = gene_lookup(gene)\n",
    "        if gene_id in gene_ids:\n",
    "            print(f\"{gene} ID ({gene_id}) already found\")\n",
    "            return None\n",
    "        elif gene_id == 'None':\n",
    "            print(f\"{gene} not found\")\n",
    "            return None\n",
    "        elif gene_id == None:\n",
    "            print(f\"{gene} not found\")\n",
    "            return None\n",
    "        else:\n",
    "            gene_ids.add(gene_id)\n",
    "            all_genes[gene] = {\n",
    "                \"id\": gene_id,\n",
    "                \"label\": gene,\n",
    "                \"uri\": \"https://www.ncbi.nlm.nih.gov/gene/%s\"%gene_id\n",
    "            }\n",
    "            return all_genes[gene]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format data for UI ingestion\n",
    "This produces a nodes list that is compatible with the KG UI ingestion script. Nodes require two columns, id and label. Note that we only have one node type, Transcription Factor, so we only require one node file. Since the TF names are inherently unique, the TF name will be used for both fields. \n",
    "\n",
    "The KG UI edges require three fields: source, relation, and target. We have two relation types, upregulation and downregulation, so we need to produce two edge files. For the edges, we include the z-score and p-value as metadata for each relationship. This enables us to filter the network edges in the website by significance. \n",
    "\n",
    "The file names for both the node and edge files are formatted to be compatible with the KG UI ingestion script and should not be changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11 TFs were found to be formatted differently in NCBI than in the network. These substitutions update the gene names to reflect NCBI formatting. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the nodes. Each node has a gene ID (id), gene symbol (label), and URI (metadata).\\\n",
    "`[id,label,metadata]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the label used to describe the node type\n",
    "node_name = \"Transcription Factor\"\n",
    "\n",
    "# collect all unique source and target nodes\n",
    "nodes = set() \n",
    "for (source, target), group in final_edge_list.groupby(['source','target']):\n",
    "    nodes.add(source)\n",
    "    nodes.add(target)\n",
    "\n",
    "metanodes = {node: get_gene_meta(node) for node in nodes}\n",
    "metanode_df = pd.DataFrame(metanodes)\n",
    "metanode_df.T.to_csv(f\"{assertions_dir}/{node_name}.nodes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Format the edges. The ID used to identify each node is the gene ID. Find these IDs and create the edges. We include the p-value and z-score as metadata in order to allow edge sorting. \\\n",
    "`[source, relation, target, z-score, p-value]` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert source and target labels to IDs\n",
    "final_edge_list['sourceID'] = final_edge_list['source'].apply(lambda x: get_gene_meta(x)['id'] if get_gene_meta(x) is not None else x)\n",
    "final_edge_list['targetID'] = final_edge_list['target'].apply(lambda x: get_gene_meta(x)['id'])\n",
    "\n",
    "# reorder the index to match ingestion format\n",
    "new_order = ['sourceID','relation','targetID','z-score','p-value','source','target']\n",
    "\n",
    "reordered_df = final_edge_list[new_order]\n",
    "reordered_df.rename(columns={'sourceID':'source','targetID':'target','z-score':'z_score','p-value':'p_value','source':'source_label','target':'target_label'}, inplace=True)\n",
    "\n",
    "# rename relations to be more descriptive\n",
    "relation_rename = {\n",
    "    '+': 'upregulates',\n",
    "    '-': 'downregulates'\n",
    "}\n",
    "reordered_df.loc[:,'relation'] = reordered_df.loc[:,'relation'].replace(relation_rename)\n",
    "reordered_df.sort_values(by=['z_score'],ascending=False, inplace=True)\n",
    "\n",
    "# split the edge list based on relation type and save to two files\n",
    "for relation in reordered_df['relation'].unique():\n",
    "    filtered_df = reordered_df[reordered_df['relation'] == relation]\n",
    "    file_name = f\"{assertions_dir}/{node_name}.{relation}.{node_name}.edges.csv\"\n",
    "    filtered_df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histogram figures of source edge count, target edge count, and edge p-value distributions\n",
    "By default, figures will be saves as PNGs. You can adjust the DPI or change the filetype to SVG below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputdir = f'{assertions_dir}/summary_figures'\n",
    "outputtype = 'png'\n",
    "network_type = 'node_weighted'\n",
    "path_to_network = f'./filtered_edge_list/{network_type}/p_sorted_edge_stats.csv'\n",
    "dpi=300\n",
    "figsize=(8,6)\n",
    "\n",
    "if not os.path.exists(outputdir):\n",
    "    os.makedirs(outputdir)\n",
    "\n",
    "network = pd.read_csv(path_to_network, delimiter = '\\t', usecols=['source', 'target', 'p-value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_histogram(items, logbins, xlabel, ylabel, fig_name, ylog=False):\n",
    "    _, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    ax.hist(items, bins=logbins, color='black')\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    \n",
    "    if ylog:\n",
    "        ax.set_yscale('log')\n",
    "\n",
    "    ax.set_xlabel(xlabel, fontsize=14)\n",
    "    ax.set_ylabel(ylabel, fontsize=14)\n",
    "\n",
    "    ax.tick_params(axis='x', labelsize=12)\n",
    "    ax.tick_params(axis='y', labelsize=12)\n",
    "\n",
    "    plt.savefig(f'{outputdir}/{fig_name}.{outputtype}', dpi=dpi)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source edges per TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sources = network['source'].value_counts()\n",
    "logbins = np.logspace(0,4,100)\n",
    "plot_histogram(sources, logbins, \"Sources per transcription factor\", \"Nodes\", \"source_histo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Target edges per TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = network['target'].value_counts() \n",
    "logbins = np.logspace(0, 3.1,100)\n",
    "plot_histogram(targets, logbins, \"Targets per transcription factor\", \"Nodes\", \"target_histo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edge significance by p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pvalue = network['p-value']\n",
    "logbins = np.logspace(-17,0,100)\n",
    "plot_histogram(pvalue, logbins, \"Edge p-value\", \"Edges\", \"pvalue_histo\", ylog=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.13 ('harmonizomeETL')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3ad6724d56c4b72bd8e5b8da3c2e0dcf6d86fdd164f3c98d6d6a78c076afabab"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
