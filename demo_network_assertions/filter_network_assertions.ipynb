{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter TF network edges by expected counts\n",
    "Here we filter by significance the human TF interactions in the edge list produced by `construct_edge_list.ipynb`. Significance is determined by comparing the observed edge count to an average edge count produced by randomly shuffling the network. We test three shuffling methods: \n",
    "1. 'signature shuffling': this method randomly shuffles the target gene sets linked to each source, then produces a new edge count matrix\n",
    "2. 'node shuffling': this method reconstructs edges by randomly sampling a source node and target node from a weighted distribution, then drawing an edge between the two\n",
    "3. 'edge shuffling': this method builds an edge list by randomly sampling (source,target) edges from a weighted distribution. \n",
    "\n",
    "\n",
    "The second part of this notebook formats the edge list into neo4j assertions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import required packages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import statistics \n",
    "import scipy.stats as stats\n",
    "import tqdm\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optional -- set a random seed to ensure reproducibility "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(314)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set default directories\n",
    "- `input` should be the output directory from `construct_edge_list.ipynb`\n",
    "- `raw_data` should be the same raw data folder used in `construct_edge_list.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = './edge_constructing_files'\n",
    "output = './filter_assertions_out'\n",
    "raw_data = './raw_data'\n",
    "assertions_dir = './kg_assertions_for_neo4j'\n",
    "benchmark_folder = output + '/benchmarking_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload edge matrix to a dataframe and format it as a multiindex, where the index is a tuple of (source, target, direction). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_file = f\"{output}/unfiltered_edge_list.csv\"\n",
    "\n",
    "initial_counts = pd.read_csv(initial_file)\n",
    "\n",
    "initial_sources = initial_counts['source'].unique()\n",
    "initial_targets = initial_counts['target'].unique()\n",
    "\n",
    "initial_counts.set_index([\"source\", \"target\", \"direction\"], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate expected edge counts\n",
    "The general procedure for filtering expected counts is:\n",
    "1. Produce a randomly shuffled edge count matrix using one of the below methods\n",
    "2. Calculate the average and standard deviation of counts for each edge after N iterations\n",
    "3. Calculate the z-score and p-value of the observed edge counts compared to expected\n",
    "4. Remove any insignificant counts\n",
    "\n",
    "Three methods of generating expected counts are provided. To test all three methods, run the cells corresponding to one method, then proceed to \"Filter results by expected counts\". Repeat for all methods.   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the number of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_TRIALS = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Signature shuffling\n",
    "Shuffle signature sets between source TFs and recalculate counts "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the benchmark method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_method = 'signature_shuffling'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload `tf_transpose.gmt` from `edge_constructing_files`. This creates a dictionary formatted as `tf:[signature1 ... signatureN]`, where each signature is a gene set enriched for that TF.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signature_file = f\"{input}/tf_transpose.gmt\"\n",
    "signature_sets = defaultdict(set)\n",
    "\n",
    "with open(signature_file, \"r\") as file:\n",
    "    for line in tqdm.tqdm(file):\n",
    "        tf, *signature = line.strip().split()\n",
    "        signature_sets[tf] = set(signature)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload RummaGEO gene sets -- we need this again to be able to reproduce the edge count matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_gmt(path):\n",
    "  gmt = {}\n",
    "  print(\"Reading {}\".format(path))\n",
    "  with open(path, \"r\") as file:\n",
    "    for line in tqdm.tqdm(file):\n",
    "      # 'id' refers to up or down tag\n",
    "      signature, id, *tf = line.strip().split()\n",
    "      gmt[\" \".join([signature, id])] = set(tf)\n",
    "\n",
    "  return gmt\n",
    "\n",
    "geo_gmt = read_gmt(f\"{raw_data}/human-geo-auto.gmt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recalculate counts:\\\n",
    "First, shuffle the signature sets between TFs.\\\n",
    "Next, count all edges using the same edge-counting procedure as in construct_edge_list.ipynb. Since we repeat this multiple time, each edge count is actually an array of counts (one count for each iteration):\n",
    "```\n",
    "{ source: { \n",
    "    target: { \n",
    "            '+': np.array(up_counts_all_trials)\n",
    "            '-': np.array(dn_counts_all_trials)\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_signatures(signature_sets):\n",
    "    tfs = list(signature_sets.keys())\n",
    "    sigs = list(signature_sets.values())\n",
    "    random.shuffle(sigs)\n",
    "    shuffled_sigsets = dict(zip(tfs, sigs))\n",
    "    return shuffled_sigsets\n",
    "\n",
    "all_high_tfs = list(signature_sets.keys())\n",
    "\n",
    "expected_counts = {source : {target : {\n",
    "    \"+\": np.zeros(N_TRIALS),\n",
    "    \"-\": np.zeros(N_TRIALS),\n",
    "  } for target in all_high_tfs} for source in all_high_tfs}\n",
    "\n",
    "for i in tqdm.tqdm(range(N_TRIALS)):\n",
    "  shuffled_sets = shuffle_signatures(signature_sets)\n",
    "\n",
    "  # Calculate counts\n",
    "  for source in all_high_tfs:\n",
    "    for signature in shuffled_sets[source]:\n",
    "\n",
    "      spl = signature.rsplit(\"-\", 1)\n",
    "      dir = \"+\" if spl[1] == \"up\" else \"-\" # \"dn\"\n",
    "      joined_sig = \" \".join(spl)\n",
    "\n",
    "      # if the gene set name is in the keys for the rummaGEO GMT\n",
    "      if joined_sig in geo_gmt.keys():\n",
    "        for target in all_high_tfs:\n",
    "          if target in geo_gmt[joined_sig]: \n",
    "            expected_counts[source][target][dir][i] += 1\n",
    "    \n",
    "      else:\n",
    "        raise Exception(\"Signature {} not found\".format(joined_sig))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Node weighted\n",
    "Randomly generate new edges by randomly selecting (weighted) source and target nodes independently   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the benchmark method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_method = 'node_weighted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the weighted distribution for source and target nodes by calculating the proportion of all edges that involve a unique node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_counts = initial_counts.groupby(['source']).sum()\n",
    "target_counts = initial_counts.groupby(['target']).sum()\n",
    "\n",
    "source_weights = source_counts['count'].tolist()\n",
    "target_weights = target_counts['count'].tolist()\n",
    "\n",
    "num_s_edges = sum(source_weights)\n",
    "num_t_edges = sum(target_weights)\n",
    "\n",
    "source_labels = source_counts.index.tolist()\n",
    "target_labels = target_counts.index.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the expected counts by sampling a set of N random source and target nodes and drawing an edge between each pair, where N = the number of edges in the input edge list. Count the number of times each (source,target) edge occurs. Finally, convert the edge count matrix to a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_counts = {source : {target : {\n",
    "    \"+\": np.zeros(N_TRIALS),\n",
    "    \"-\": np.zeros(N_TRIALS),\n",
    "  } for target in initial_targets} for source in initial_sources}\n",
    "\n",
    "for i in tqdm.tqdm(range(N_TRIALS)):\n",
    "        # Perform weighted random choice\n",
    "        random_source = random.choices(source_labels, weights=source_weights, k=num_s_edges)\n",
    "        random_target = random.choices(target_labels, weights=target_weights, k=num_t_edges)\n",
    "          \n",
    "        if len(random_source) != len(random_target):\n",
    "                print('Source length != target length')\n",
    "        else:\n",
    "                for source, target in zip(random_source, random_target):\n",
    "                        # randomly choose an edge direction\n",
    "                        direction = random.randint(0,1)\n",
    "                        if direction == 0:\n",
    "                                expected_counts[source][target][\"+\"][i] += 1\n",
    "                        else:\n",
    "                                expected_counts[source][target][\"-\"][i] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 3: Edge weighted\n",
    "Instead of sampling source and target nodes independently, produce a weighted distribution of edges based on their initial counts. Randomly sample N edges, where N is the size of the original edge matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the benchmark method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_method = 'edge_weighted'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Produce a weighted distribution of edges using their counts in the input edge list. Randomly sample N edges from this distribution, where N is the size of the input edge list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_random_edges():\n",
    "        # get the weights\n",
    "        edge_counts = initial_counts.groupby(['source', 'target']).sum()\n",
    "        edge_weights = edge_counts['count'].tolist()\n",
    "\n",
    "        # get the total number of edges counted\n",
    "        num_edges = sum(edge_weights)\n",
    "\n",
    "        # get the labels in the same order as their weights\n",
    "        edge_labels = edge_counts.index.tolist()\n",
    "\n",
    "        # randomly select the same number of sources as in the original edge list\n",
    "        random_edges = random.choices(edge_labels, weights=edge_weights, k=num_edges)\n",
    "\n",
    "        return random_edges\n",
    "\n",
    "# initialize expected counts\n",
    "expected_counts = {source : {target : {\n",
    "    \"+\": np.zeros(N_TRIALS),\n",
    "    \"-\": np.zeros(N_TRIALS),\n",
    "  } for target in initial_targets} for source in initial_sources}\n",
    "\n",
    "for i in tqdm.tqdm(range(N_TRIALS)):\n",
    "        # Perform weighted random choice\n",
    "        random_edges = find_random_edges()     \n",
    "\n",
    "        for index in random_edges:\n",
    "                # extract the source, target and randomly assign a direction\n",
    "                source, target = index\n",
    "\n",
    "                # randomly choose an edge direction\n",
    "                direction = random.randint(0,1)\n",
    "\n",
    "                if direction == 0:\n",
    "                        expected_counts[source][target][\"+\"][i] += 1\n",
    "                else:\n",
    "                        expected_counts[source][target][\"-\"][i] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter results using expected counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, calculate the edge statistics using the expected counts - observed counts, expected counts, mean, stdev, z-score, and p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a similar array to store stats\n",
    "hindex = pd.MultiIndex.from_product([initial_sources, initial_targets,['+', '-']],\n",
    "  names = [\"source\", \"target\", \"relation\"])\n",
    "edge_statistics = pd.DataFrame(index = hindex, columns = [\"observed\", \"expected\", \"expected stdev\", \"z-score\", \"p-value\"])\n",
    "\n",
    "\n",
    "for source in tqdm.tqdm(initial_sources):\n",
    "  for target in initial_targets:\n",
    "    for dir in ['+','-']:\n",
    "      trial_counts = expected_counts[source][target][dir]\n",
    "\n",
    "      # find expected and observed counts -- if the key doesn't exist, then the observed counts are zero\n",
    "      try:\n",
    "        obsv_counts = initial_counts.loc[(source, target, dir), 'count']\n",
    "      except KeyError:\n",
    "        obsv_counts = 0\n",
    "\n",
    "      # calculate statistics \n",
    "      mean = statistics.mean(trial_counts)\n",
    "      stdev = statistics.stdev(trial_counts)\n",
    "\n",
    "      # ignore values with no stdev and obsv counts == 0\n",
    "      if stdev != 0:\n",
    "        z_score = (obsv_counts - mean) / (stdev)\n",
    "        p_value = 1 - stats.norm.cdf(z_score)\n",
    "\n",
    "        # store in dataframe, removing non-existent edges\n",
    "        if obsv_counts > 0:\n",
    "          edge_statistics.loc[(source, target, dir)] = [obsv_counts, mean, stdev, z_score, p_value]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove insignificant edges.\\\n",
    "*Z-score is the chosen method because it allows for finer filtering. Uncomment p-vaue as desired.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop NAs\n",
    "edge_statistics.dropna(inplace=True)\n",
    "\n",
    "z_sorted = edge_statistics.sort_values(by='z-score', ascending = False)\n",
    "# p_sorted = edge_statistics.sort_values(by='p-value')\n",
    "\n",
    "Z_MIN = 2.325\n",
    "# P_MIN = 1e-12\n",
    "\n",
    "# OR - optional - read in from file: \n",
    "# benchmark_method = 'signature_shuffling'\n",
    "# edge_statistics = pd.read_csv(f'/Users/anna/Projects/KG_UI/build_TF_network/filter_assertions_out/benchmarking/{benchmark_method}/{benchmark_method}_z_sorted_edge_stats.csv', delimiter = '\\t')\n",
    "\n",
    "edge_statistics.set_index(['source', 'target','relation'], inplace=True)\n",
    "\n",
    "significant_edges = edge_statistics.loc[((edge_statistics['z-score'] != float('Inf')) & (edge_statistics['z-score'] > Z_MIN))]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For pairs that have significant edges in both directions, keep only the edge with the most significance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work from a copy since we're removing entries directly\n",
    "significant_edges_copy = significant_edges.copy()\n",
    "direction_edges_to_drop = []\n",
    "\n",
    "# search source-target pairs and retain only the edge with the highest significance \n",
    "for (source, target), group in significant_edges_copy.groupby(level=['source', 'target']):\n",
    "\n",
    "    directions = group.index.get_level_values('relation')\n",
    "    up_exists = '+' in directions\n",
    "    dn_exists = '-' in directions\n",
    "\n",
    "    # remove either up or down if both are significant\n",
    "    if up_exists and dn_exists:\n",
    "        # Filter to get '+' and '-' entries\n",
    "        up_data = group.loc[(slice(None), slice(None), '+'), :]\n",
    "        dn_data = group.loc[(slice(None), slice(None), '-'), :]   \n",
    "\n",
    "        # remove lower z-score\n",
    "        if up_data['z-score'].values[0] < dn_data['z-score'].values[0]:\n",
    "          direction_edges_to_drop.append((source, target, '+')) \n",
    "        else:\n",
    "          direction_edges_to_drop.append((source, target, '-'))\n",
    "\n",
    "significant_edges_copy.drop(direction_edges_to_drop, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to prevent the final network from being too dense to visualize, limit the maximum number of outgoing ('source') edges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep only the top 3 most significant edges from each source \n",
    "max_src_edges = 3\n",
    "significant_edges_copy.sort_values(by=['source','z-score'], inplace=True)\n",
    "final_edge_list = significant_edges_copy.groupby(level='source').head(max_src_edges)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save collected statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_sorted.to_csv(f\"{benchmark_folder}/{benchmark_method}_z_sorted_edge_stats.csv\", sep='\\t')\n",
    "# p_sorted.to_csv(f\"{output}/p_sorted_edge_statistics\", sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save edge list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_edge_list.to_csv(f\"{benchmark_folder}/{benchmark_method}/edge_list_filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format data for UI ingestion\n",
    "This produces a nodes list that is compatible with the KG UI ingestion script. Nodes require two columns, id and label. Note that we only have one node type, Transcription Factor, so we only require one node file. Since the TF names are inherently unique, the TF name will be used for both fields. The KG UI edges require three fields: source, relation, and target. We have two relation types, upregulation and downregulation, so we need to produce two edge files. \n",
    "\n",
    "The file names for both the node and edge files are formatted to be compatible with the KG UI ingestion script and should not be changed.\n",
    "\n",
    "Format nodes: [id,label]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the label used to describe the node type\n",
    "node_name = \"Transcription Factor\"\n",
    "\n",
    "# collect all unique source and target nodes\n",
    "nodes = set() \n",
    "for (source, target), group in final_edge_list.groupby(level=['source', 'target']):\n",
    "    nodes.add((source, source))\n",
    "    nodes.add((target, target))\n",
    "\n",
    "node_df = pd.DataFrame(list(nodes), columns=['id', 'label'])\n",
    "node_df.to_csv(f'{benchmark_folder}/{benchmark_method}/{node_name}.nodes.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reformat the edges: [source, relation, target] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder the index to match ingestion format\n",
    "new_index = ['source','relation','target']\n",
    "index_frame = final_edge_list.index.to_frame()\n",
    "index_frame = index_frame[new_index]\n",
    "\n",
    "# rename relations to be more descriptive\n",
    "relation_rename = {\n",
    "    '+': 'upregulates',\n",
    "    '-': 'downregulates'\n",
    "}\n",
    "index_frame['relation'] = index_frame['relation'].replace(relation_rename)\n",
    "\n",
    "# split the edge list based on relation type and save to two files\n",
    "relation_types = index_frame['relation'].unique()\n",
    "\n",
    "for relation in relation_types:\n",
    "    filtered_df = index_frame[index_frame['relation'] == relation]\n",
    "    file_name = f\"{benchmark_folder}/{benchmark_method}/{node_name}.{relation}.{node_name}.edges.csv\"\n",
    "    filtered_df.to_csv(file_name, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL - plot histograms of counts data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot log-scaled histogram of counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot log-scaled histogram of counts\n",
    "\n",
    "def tf_histogram(name, counts, num_bins=300, fig_size=(10,6)):\n",
    "    plt.figure(figsize=fig_size)\n",
    "    plt.hist(counts, bins = num_bins, edgecolor ='none')\n",
    "    plt.yscale('log')\n",
    "    plt.xlabel('Interaction count', fontsize=14)\n",
    "    plt.ylabel('Frequency', fontsize=14)\n",
    "    if name == \"all\":\n",
    "        plt.title('All TF-TF interaction counts', fontsize=16)\n",
    "    elif name == \"pos\":\n",
    "        plt.title('Positive interaction counts', fontsize=16)\n",
    "    elif name == \"neg\": \n",
    "        plt.title('Negative interaction counts', fontsize=16)\n",
    "\n",
    "\n",
    "# get count values\n",
    "all_counts = final_edge_list['observed']\n",
    "# Filter the DataFrame for rows where the direction is \"+\"\n",
    "positive_counts = final_edge_list.loc[(slice(None), slice(None), \"+\"), :]['observed']\n",
    "# Filter the DataFrame for rows where the direction is \"+\"\n",
    "negative_counts = final_edge_list.loc[(slice(None), slice(None), \"-\"), :]['observed']\n",
    "\n",
    "tf_histogram(\"all\", all_counts)\n",
    "plt.savefig(f\"{output}/img/all_histo_filtered_weighted_shuffling.png\")\n",
    "plt.show()\n",
    "\n",
    "tf_histogram(\"pos\", positive_counts)\n",
    "plt.savefig(f\"{output}/img/pos_histo_filtered_weighted_shuffling.png\")\n",
    "plt.show()\n",
    "\n",
    "tf_histogram(\"neg\", negative_counts)\n",
    "plt.savefig(f\"{output}/img/neg_histo_filtered_weighted_shuffling.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
