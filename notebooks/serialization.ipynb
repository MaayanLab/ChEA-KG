{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serializing GMT Files to CSV\n",
    "In this notebook we'll convert GMT files from [Enrichr](https://maayanlab.cloud/Enrichr) to CSV files that can be ingested in the graph database. This includes several steps:\n",
    "1. Mapping/ generating ids to the terms\n",
    "2. Mapping genes to their Entrez ID\n",
    "3. Creating the CSV file\n",
    "\n",
    "## CSV Serialization\n",
    "Nodes and edges are serialized differently for our knowledge graph. \n",
    "\n",
    "### Node Serialization\n",
    "Serialized nodes requires two columns: id and label. Optionally, you can add more columns for additional metadata. CSV file should be formatted this way: `<node_type>.node.csv` for it to be compatible with the provided ingestion script. This means for our GMT files, we need two node files: (1) label type, and (2) genes\n",
    "\n",
    "|      |   id          |   label                                                                    |   ontology_label                                              |   uri                                                  |\n",
    "|------|---------------|----------------------------------------------------------------------------|---------------------------------------------------------------|--------------------------------------------------------|\n",
    "|   0  |   GO:0051084  |   'de novo' posttranslational protein folding (GO:0051084)                 |   'de novo' posttranslational protein folding                 |   http://amigo.geneontology.org/amigo/term/GO:0051084  |\n",
    "|   1  |   GO:0006103  |   2-oxoglutarate metabolic process (GO:0006103)                            |   2-oxoglutarate metabolic process                            |   http://amigo.geneontology.org/amigo/term/GO:0006103  |\n",
    "|   2  |   GO:0050428  |   3'-phosphoadenosine 5'-phosphosulfate biosynthetic process (GO:0050428)  |   3'-phosphoadenosine 5'-phosphosulfate biosynthetic process  |   http://amigo.geneontology.org/amigo/term/GO:0050428  |\n",
    "|   3  |   GO:0050427  |   3'-phosphoadenosine 5'-phosphosulfate metabolic process (GO:0050427)     |   3'-phosphoadenosine 5'-phosphosulfate metabolic process     |   http://amigo.geneontology.org/amigo/term/GO:0050427  |\n",
    "|   4  |   GO:0061158  |   3'-UTR-mediated mRNA destabilization (GO:0061158)                        |   3'-UTR-mediated mRNA destabilization                        |   http://amigo.geneontology.org/amigo/term/GO:0061158  |\n",
    "|   5  |   GO:0070935  |   3'-UTR-mediated mRNA stabilization (GO:0070935)                          |   3'-UTR-mediated mRNA stabilization                          |   http://amigo.geneontology.org/amigo/term/GO:0070935  |\n",
    "\n",
    "### Edge Serialization\n",
    "\n",
    "Meanwhile, edges require (1) source id, (2) the relation, and (3) target id columns. The rest are optional metadata. CSV file should be formatted as follows: `<source_node_type>.<relation>.<target_node_type>.edges.csv`.\n",
    "\n",
    "|      |   source  |   relation  |   target      |   source_label  |   target_label                                              |   resource       |   link_to_resource          |\n",
    "|------|-----------|-------------|---------------|-----------------|-------------------------------------------------------------|------------------|-----------------------------|\n",
    "|   0  |   23753   |   GO BP     |   GO:0051084  |   SDF2L1        |   'de novo' posttranslational protein folding (GO:0051084)  |   Gene Ontology  |   http://geneontology.org/  |\n",
    "|   1  |   3313    |   GO BP     |   GO:0051084  |   HSPA9         |   'de novo' posttranslational protein folding (GO:0051084)  |   Gene Ontology  |   http://geneontology.org/  |\n",
    "|   2  |   10576   |   GO BP     |   GO:0051084  |   CCT2          |   'de novo' posttranslational protein folding (GO:0051084)  |   Gene Ontology  |   http://geneontology.org/  |\n",
    "|   3  |   6767    |   GO BP     |   GO:0051084  |   ST13          |   'de novo' posttranslational protein folding (GO:0051084)  |   Gene Ontology  |   http://geneontology.org/  |\n",
    "|   4  |   3310    |   GO BP     |   GO:0051084  |   HSPA6         |   'de novo' posttranslational protein folding (GO:0051084)  |   Gene Ontology  |   http://geneontology.org/  |\n",
    "|   5  |   957     |   GO BP     |   GO:0051084  |   ENTPD5        |   'de novo' posttranslational protein folding (GO:0051084)  |   Gene Ontology  |   http://geneontology.org/  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "import uuid"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gene Mapper\n",
    "To start our conversion, we need a way to map the gene names to their respective gene ids. The following code downloads the metadata for Homo sapiens genes from NCBI gene and creates a mapper that returns the gene id. It does this by (1) mapping gene labels to ID, (2) mapping synonyms to ID, (3) mapping upper case gene labels and synonyms to ids. (3) is done to address the fact that Enrichr gene names are all upper case. Ambiguous labels (i.e. names with multiple ids) are removed from the map. The function `get_gene_meta` extends this and returns a dictionary containing the gene id, label, and uri which can be used for our serialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_save_read(url, file, reader=pd.read_csv, sep='\\t', **kwargs):\n",
    "  ''' Download file from {url}, save it to {file}, and subsequently read it with {reader} using pandas options on {**kwargs}.\n",
    "  '''\n",
    "  if not os.path.exists(file):\n",
    "    if os.path.dirname(file):\n",
    "      os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    df = reader(url, sep=sep, index_col=None)\n",
    "    df.to_csv(file, sep=sep, index=False)\n",
    "  return pd.read_csv(file, sep=sep, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "organism = \"Mammalia/Homo_sapiens\"\n",
    "url = 'ftp://ftp.ncbi.nih.gov/gene/DATA/GENE_INFO/{}.gene_info.gz'.format(organism)\n",
    "file = '{}.gene_info.tsv'.format(organism)\n",
    "\n",
    "ncbi_gene = fetch_save_read(url, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maybe_split(record):\n",
    "    ''' NCBI Stores Nulls as '-' and lists '|' delimited\n",
    "    '''\n",
    "    if record in {'', '-'}:\n",
    "        return set()\n",
    "    return set(record.split('|'))\n",
    "\n",
    "def supplement_dbXref_prefix_omitted(ids):\n",
    "    ''' NCBI Stores external IDS with Foreign:ID while most datasets just use the ID\n",
    "    '''\n",
    "    for id in ids:\n",
    "        # add original id\n",
    "        yield id\n",
    "        # also add id *without* prefix\n",
    "        if ':' in id:\n",
    "            yield id.split(':', maxsplit=1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi_gene['All_synonyms'] = [\n",
    "    set.union(\n",
    "      maybe_split(gene_info['Symbol']),\n",
    "      maybe_split(gene_info['Symbol_from_nomenclature_authority']),\n",
    "      maybe_split(str(gene_info['GeneID'])),\n",
    "      maybe_split(gene_info['Synonyms']),\n",
    "      maybe_split(gene_info['Other_designations']),\n",
    "      maybe_split(gene_info['LocusTag']),\n",
    "      set(supplement_dbXref_prefix_omitted(maybe_split(gene_info['dbXrefs']))),\n",
    "    )\n",
    "    for _, gene_info in ncbi_gene.iterrows()\n",
    "  ]\n",
    "\n",
    "synonyms, gene_id = zip(*{\n",
    "    (synonym, gene_info['GeneID'])\n",
    "    for _, gene_info in ncbi_gene.iterrows()\n",
    "    for synonym in gene_info['All_synonyms']\n",
    "  })\n",
    "ncbi_lookup_syn = pd.Series(gene_id, index=synonyms)\n",
    "symbols, cap, gene_id = zip(*{\n",
    "    (gene_info['Symbol'], gene_info['Symbol'].upper(), gene_info['GeneID'])\n",
    "    for _, gene_info in ncbi_gene.iterrows()\n",
    "  })\n",
    "ncbi_lookup_sym = pd.Series(gene_id, index=symbols)\n",
    "ncbi_lookup_sym_cap = pd.Series(gene_id, index=cap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_values = ncbi_lookup_syn.index.value_counts()\n",
    "ambiguous = index_values[index_values > 1].index\n",
    "ncbi_lookup_syn_disambiguated = ncbi_lookup_syn[(\n",
    "(ncbi_lookup_syn.index == ncbi_lookup_syn) | (~ncbi_lookup_syn.index.isin(ambiguous))\n",
    ")]\n",
    "def gene_lookup(gene):\n",
    "    gene_id = ncbi_lookup_sym.to_dict().get(gene)\n",
    "    if gene_id: return str(gene_id)\n",
    "    gene_id = ncbi_lookup_sym_cap.to_dict().get(gene)\n",
    "    if gene_id: return str(gene_id)\n",
    "    return str(ncbi_lookup_syn_disambiguated.to_dict().get(gene))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'None'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_lookup(\"H4-16\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': '9276',\n",
       " 'label': 'COPB2',\n",
       " 'uri': 'https://www.ncbi.nlm.nih.gov/gene/9276'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_genes = {}\n",
    "gene_ids = set()\n",
    "def get_gene_meta(gene):\n",
    "    if gene in all_genes:\n",
    "        return all_genes[gene]\n",
    "    else:\n",
    "        gene_id = gene_lookup(gene)\n",
    "        if gene_id in gene_ids:\n",
    "            return None\n",
    "        elif gene_id == 'None':\n",
    "            return None\n",
    "        elif gene_id == None:\n",
    "            return None\n",
    "        else:\n",
    "            gene_ids.add(gene_id)\n",
    "            all_genes[gene] = {\n",
    "                \"id\": gene_id,\n",
    "                \"label\": gene,\n",
    "                \"uri\": \"https://www.ncbi.nlm.nih.gov/gene/%s\"%gene_id\n",
    "            }\n",
    "            return all_genes[gene]\n",
    "\n",
    "get_gene_meta(\"COPB2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gene_meta('H4-16')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the GMT files from Enrichr\n",
    "The following code downloads the GMT file from Enrichr. This function checks the existence of the file locally before downloading it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_save_library(library, file):\n",
    "  ''' Download file from {url}, save it to {file}, and subsequently read it with {reader} using pandas options on {**kwargs}.\n",
    "  '''\n",
    "  if not os.path.exists(file):\n",
    "    if os.path.dirname(file):\n",
    "      os.makedirs(os.path.dirname(file), exist_ok=True)\n",
    "    gmt_url = \"https://maayanlab.cloud/Enrichr/geneSetLibrary?mode=text&libraryName=%s\"%library\n",
    "    res = requests.get(gmt_url)\n",
    "    gmt = res.text\n",
    "    with open(file, 'w') as o:\n",
    "        o.write(gmt)\n",
    "  \n",
    "  with open(file) as o:\n",
    "    return o.read().strip().split(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serializing GMT Files\n",
    "Now that we have everything we need, let's try converting some Enrichr libraries to CSV files. Before we start let's define first a dictionary to store all the gene metadata. We'll use this to generate a combined gene node csv file later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using regular expression to get the term id: GO_Biological_Process_2021\n",
    "The following code block downloads the gmt file if it does not exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'de novo' posttranslational protein folding (GO:0051084)\t\tSDF2L1\tHSPA9\tCCT2\tST13\tHSPA6\tENTPD5\tHSPA5\tPTGES3\tHSPA1L\tHSPA8\tDNAJB13\tHSPA2\tDNAJB14\tHSPE1\tDNAJC18\tGAK\tDNAJC7\tDNAJB12\tHSPA1A\tHSPA1B\tERO1A\tSELENOF\tHSPA14\tHSPA13\tDNAJB1\tCHCHD4\tBAG1\tDNAJB5\tDNAJB4\tSDF2\tUGGT1\t\n"
     ]
    }
   ],
   "source": [
    "library = \"GO_Biological_Process_2021\"\n",
    "filename = \"gmt/%s.gmt\"%library\n",
    "gmt = fetch_and_save_library(library, filename)\n",
    "print(gmt[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing the nodes\n",
    "For this GMT file, notice that the label already contains a persistent id that we can use as a node id. We can extract it by utilizing regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_set_name_resolver(name):\n",
    "    regex=\"(?P<label>(?P<ontology_label>.+) \\((?P<id>GO\\:.+)\\))\"\n",
    "    props = re.search(regex, name).groupdict()\n",
    "    props[\"uri\"] = \"http://amigo.geneontology.org/amigo/term/%s\"%props[\"id\"]\n",
    "    return props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': \"'de novo' posttranslational protein folding (GO:0051084)\",\n",
       " 'ontology_label': \"'de novo' posttranslational protein folding\",\n",
       " 'id': 'GO:0051084',\n",
       " 'uri': 'http://amigo.geneontology.org/amigo/term/GO:0051084'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gene_set_name_resolver(gmt[0].split(\"\\t\\t\")[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Serializing the edges\n",
    "\n",
    "Now that we have a way to get process the term and gene nodes, let's now get to serializing edges. For a GMT file, we say that an edge exists between a gene and a term if the gene is part of that term's gene set, that is if we have the following:\n",
    "```\n",
    "Term 1      Gene 1  Gene 2  Gene 3\n",
    "Term 2      Gene 2  Gene 4  Gene 5\n",
    "```\n",
    "Then we say that there is an edge between Term 1 and Gene 1, Gene 2, and Gene 3, and Term 2 and Gene 2, Gene 4, and Gene 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterate_gmt(gmt, term_node, relation, gene_set_name_resolver, resource=None, edge_properties={}):\n",
    "    terms = []\n",
    "    edges = []\n",
    "    for line in tqdm(gmt):\n",
    "        term, *genes = line.strip().split(\"\\t\")\n",
    "        genes = genes[1:]\n",
    "        term_meta = gene_set_name_resolver(term)\n",
    "        if term_meta:\n",
    "            direction = term_meta.pop('direction', None)\n",
    "            term_id = term_meta[\"id\"]\n",
    "            terms.append(term_meta)\n",
    "            for gene in genes:\n",
    "                gene_meta = get_gene_meta(gene)\n",
    "                if gene_meta:\n",
    "                    if type(gene_meta) == str:\n",
    "                        print(gene, gene_meta)\n",
    "                    gene_id = gene_meta[\"id\"]\n",
    "                    edge = {\n",
    "                        \"source\": term_id,\n",
    "                        \"relation\": relation,\n",
    "                        \"target\": gene_id,\n",
    "                        \"source_label\": term,\n",
    "                        \"target_label\": gene,\n",
    "                        **edge_properties.get((term, gene), {})\n",
    "                    }\n",
    "                    if resource:\n",
    "                        edge[\"resource\"] = resource\n",
    "                    if direction:\n",
    "                        edge[\"direction\"] = direction\n",
    "                    edges.append(edge)\n",
    "    term_df = pd.DataFrame.from_records(terms)\n",
    "    cols = [\"id\", \"label\"] + [i for i in term_df.columns if not i in [\"id\", \"label\"]]\n",
    "    term_df = term_df[cols]\n",
    "    term_df.to_csv(\"csv/%s.nodes.csv\"%term_node, index=False)\n",
    "    edge_df = pd.DataFrame.from_records(edges)\n",
    "    edge_df.to_csv(\"csv/%s.%s.Gene.edges.csv\"%(term_node, relation), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6036/6036 [10:22<00:00,  9.69it/s]  \n"
     ]
    }
   ],
   "source": [
    "term_node = \"GO Biological Process Term\"\n",
    "relation = \"GO BP\"\n",
    "resource = \"http://geneontology.org/\"\n",
    "iterate_gmt(gmt, term_node, relation, gene_set_name_resolver, resource)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_gene_meta('H4-16')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: MGI_Mammalian_Phenotype_Level_4_2021\n",
    "Create a `gene_set_name_resolver` function for MGI_Mammalian_Phenotype_Level_4_2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abdominal situs ambiguus MP:0011250\t\tCCDC39\tDNAH5\tINVS\tDNAH11\tDNAAF3\tFOXH1\tRPGRIP1L\tDRC1\tDNAI1\tIFT27\t\n"
     ]
    }
   ],
   "source": [
    "library = 'MGI_Mammalian_Phenotype_Level_4_2021'\n",
    "filename = \"gmt/%s.gmt\"%library\n",
    "gmt = fetch_and_save_library(library, filename)\n",
    "print(gmt[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_set_name_resolver(name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_node = \"Mouse Phenotype\"\n",
    "relation = \"MP\"\n",
    "resource = \"http://www.informatics.jax.org\"\n",
    "# iterate_gmt(gmt, term_node, relation, gene_set_name_resolver, resource)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using APIs to get the node id: KEGG_2021_Human\n",
    "If the ID is not in the term, we can use an API to create a mapping between a term and the id. This example uses the KEGG's rest API to download the pathways and their respective IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = \"KEGG_2021_Human\"\n",
    "gmt = fetch_and_save_library(library, \"gmt/%s\"%library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "kegg_pathways = {}\n",
    "res = requests.get(\"https://rest.kegg.jp/list/pathway\")\n",
    "count = 0\n",
    "for i in res.text.strip().split(\"\\n\"):\n",
    "    kid, label = i.strip().split(\"\\t\")\n",
    "    count += 1\n",
    "    kegg_pathways[label] = kid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gene_set_name_resolver(name):\n",
    "    kegg_id = kegg_pathways[name] if name in kegg_pathways else name\n",
    "    props = {\n",
    "        \"id\": kegg_id,\n",
    "        \"label\": name\n",
    "    }\n",
    "    if name in kegg_pathways:\n",
    "        props[\"uri\"] = \"https://www.genome.jp/entry/%s\"%props[\"id\"]\n",
    "    return props "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 320/320 [00:39<00:00,  8.17it/s]\n"
     ]
    }
   ],
   "source": [
    "term_node = \"KEGG Pathway\"\n",
    "relation = \"KEGG\"\n",
    "resource = \"https://www.genome.jp/kegg/\"\n",
    "iterate_gmt(gmt, term_node, relation, gene_set_name_resolver, resource)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise: Cancer_Cell_Line_Encyclopedia\n",
    "Use the [Cellosaurus API](https://api.cellosaurus.org/) to create a `gene_set_name_resolver` for Cancer_Cell_Line_Encyclopedia. You may have to redundant ids. One way to do this is to generate a uuid based on the label's name instead:\n",
    "```\n",
    "id = str(uuid.uuid5(uuid.NAMESPACE_URL, gene_set_name))\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = \"Cancer_Cell_Line_Encyclopedia\"\n",
    "gmt = fetch_and_save_library(library, \"gmt/%s\"%library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_lines = {}\n",
    "def gene_set_name_resolver(name):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_node = \"CCLE Cell Line\"\n",
    "relation = \"CCLE\"\n",
    "resource = \"https://sites.broadinstitute.org/ccle\"\n",
    "# iterate_gmt(gmt, term_node, relation, gene_set_name_resolver, resource)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Excercise: Gene.csv\n",
    "Using the `all_genes` dictionary, create a `Genes.nodes.csv` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write your code here\n",
    "genes = pd.DataFrame.from_records([i for i in all_genes.values() if not i == None])\n",
    "genes.to_csv(\"csv/Gene.nodes.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ingestion\n",
    "Ingestion is relatively simple if we followed followed the naming convention. `src/import_csv.py` is provided to do the heavy lifting. To run it just type the following on the command line:\n",
    "```\n",
    "python import_csv.py /path/to/csv/directory\n",
    "```\n",
    "This will run a bulk import of your csv files\n",
    "e.g.\n",
    "```\n",
    "python import_csv.py ../notebooks/csv\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3284736ab445d0d169a3bd7a83f7af8c4472e9894b224dc8086ef6cdac542c07"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
